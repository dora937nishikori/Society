BTM理解

・BTMの利点
ー従来よりも短い文章に対してもトピックを適切に推定できる
ー

・BTMの仕組み
ーコメント一文に含まれる二つの単語をバイタームと定義する
ーバイタームごとに同一のトピックを仮定する
ー
ーディリクレ分布のハイパーパラメータと崩壊型ギブスサンプリングによりトピック分布と単語分布が決まる
ーΘはトピック分布、これに従ってトピックが決まる
ー決まったトピックの単語分布に従って、各バイタームが生成されると仮定
ーこのトピック分布と単語分布を学習し、最適な分布にする


・何故短い文章にも適応できるのか
ー従来のモデルは、文書を単語の集合として扱い、学習する（出現頻度）
ーBTMは、バイタームの共起性をトピックの学習に用いることで、短いテキストにも適している

ーLDAは文書レベル、つまり一文に対して文書内の単語の出現頻度をもとに、トピックを学習するから、
長い文章であれば多くの単語が含まれているので、学習しやすい

ーBTMは文書全体、つまり短い文書の集合に対して、バイタームの共起性を利用してトピックを学習する
文書全体での共起性なので、一文が短くても、文書数がある程度あれば学習できる。
